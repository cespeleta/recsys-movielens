{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torchmetrics import MeanSquaredError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dynaconf import Dynaconf\n",
    "import lightning as L\n",
    "\n",
    "from src.models.mf_with_bias import MatrixFactorizationWithBias\n",
    "from src.lit_models.base import LightningModel\n",
    "\n",
    "from src.datasets.movielens import MovielensDataModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config with dynaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Dynaconf(root_path=\"configs\", settings_files=[\"config_mf.yaml\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model inputs from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=943, n_items=1625, n_factors=128\n"
     ]
    }
   ],
   "source": [
    "n_users = cfg.model.pytorch_model.init_args.n_users\n",
    "n_items = cfg.model.pytorch_model.init_args.n_items\n",
    "n_factors = cfg.model.pytorch_model.init_args.n_factors\n",
    "print(f\"{n_users=}, {n_items=}, {n_factors=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFactorizationWithBias(\n",
       "  (user_emb): Embedding(943, 128)\n",
       "  (user_bias): Embedding(943, 1)\n",
       "  (item_emb): Embedding(1625, 128)\n",
       "  (item_bias): Embedding(1625, 1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model = MatrixFactorizationWithBias(n_users, n_items, 128)\n",
    "pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"lightning_logs/embedding_dim/version_1/checkpoints/best_model.ckpt\"\n",
    "\n",
    "# load weights\n",
    "model = LightningModel.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_file, pytorch_model=pytorch_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = model.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MovielensDataModule(dataset=\"ml-100k\", target=\"rating\", batch_size=32)\n",
    "dm.setup(stage=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new data\n",
    "\n",
    "Here we are going to use test set as a new data but, of course, we could use any new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first batch of data\n",
    "for batch_data in test_dataloader:\n",
    "    users = batch_data[\"user\"].to(device)\n",
    "    items = batch_data[\"item\"].to(device)\n",
    "    ratings = batch_data[\"rating\"].to(device)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "We can make our predictions with plain Pytorch our using the Lighning Trainer.\n",
    "\n",
    "Docs: https://lightning.ai/docs/pytorch/stable/deploy/production_intermediate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9380, 2.1209, 1.5993, 2.1122, 2.0556, 1.7461, 2.0709, 1.9205, 1.8691,\n",
       "        1.5280, 1.5109, 1.1762, 1.3715, 1.8609, 2.2000, 2.2489, 2.2388, 2.3173,\n",
       "        2.0523, 2.7145, 2.6110, 2.5191, 2.5386, 1.6416, 2.2497, 2.2378, 2.0332,\n",
       "        1.7170, 2.5124, 2.0731, 2.1645, 2.2891])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_hat = model(users, items)  #* (5.5 - 1) + 1\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is equivalent to call the `forward` of the pytorch model directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9380, 2.1209, 1.5993, 2.1122, 2.0556, 1.7461, 2.0709, 1.9205, 1.8691,\n",
      "        1.5280, 1.5109, 1.1762, 1.3715, 1.8609, 2.2000, 2.2489, 2.2388, 2.3173,\n",
      "        2.0523, 2.7145, 2.6110, 2.5191, 2.5386, 1.6416, 2.2497, 2.2378, 2.0332,\n",
      "        1.7170, 2.5124, 2.0731, 2.1645, 2.2891])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    print(model.pytorch_model(users, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = MeanSquaredError().to(device)\n",
    "# pred_list = []\n",
    "# for batch_data in test_dataloader:\n",
    "#     users = batch_data[\"user\"].to(device)\n",
    "#     items = batch_data[\"item\"].to(device)\n",
    "#     ratings = batch_data[\"rating\"].to(device)\n",
    "#     with torch.inference_mode():\n",
    "#         y_hat = model.predict_step(batch_data) * (5.5 - 1) + 1\n",
    "#         pred_list.append(y_hat.cpu().detach().numpy().squeeze())\n",
    "    \n",
    "#     mse(y_hat, ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 501/501 [00:01<00:00, 361.43it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(enable_checkpointing=False)\n",
    "batched_predictions = trainer.predict(model, dataloaders=[test_dataloader])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, show first batch fo predictions. Why are they different from the pure pytorch predictions? That's because in the LightningModule predictions are transformed using `Sigmoid` to normalize the oputpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8741, 0.8929, 0.8319, 0.8921, 0.8865, 0.8515, 0.8880, 0.8722, 0.8664,\n",
       "        0.8217, 0.8192, 0.7643, 0.7976, 0.8654, 0.9003, 0.9046, 0.9037, 0.9103,\n",
       "        0.8862, 0.9379, 0.9316, 0.9255, 0.9268, 0.8378, 0.9046, 0.9036, 0.8842,\n",
       "        0.8477, 0.9250, 0.8883, 0.8970, 0.9080])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_predictions[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all predictions in a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8741, 0.8929, 0.8319,  ..., 0.7197, 0.7358, 0.6126])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = torch.cat(batched_predictions)\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get true ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3., 3.,  ..., 2., 3., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = torch.cat([batch_data[\"user\"] for batch_data in test_dataloader], dim=0)\n",
    "items = torch.cat([batch_data[\"item\"] for batch_data in test_dataloader], dim=0)\n",
    "ratings = torch.cat([batch_data[\"rating\"] for batch_data in test_dataloader], dim=0)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_predictions(x, range=(1, 5.5)):\n",
    "    min_y, max_y = range\n",
    "    return x * (max_y - min_y) + min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2.0449\n",
      "Test RMSE: 1.196\n"
     ]
    }
   ],
   "source": [
    "mse = MeanSquaredError()\n",
    "rmse = MeanSquaredError(squared=False)\n",
    "\n",
    "scaled_predictions = scale_predictions(predictions)\n",
    "\n",
    "test_mse = mse(scaled_predictions, ratings)\n",
    "test_rmse = rmse(scaled_predictions, ratings)\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RMSE: {torch.sqrt(test_rmse):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2.0449\n",
      "Test RMSE: 1.430\n"
     ]
    }
   ],
   "source": [
    "test_mae = mse.compute()\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RMSE: {torch.sqrt(test_mse):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mappng\n",
    "import joblib\n",
    "\n",
    "\n",
    "item2int = joblib.load(\"output/encoders/ml-100k/title_encoder.joblib\")\n",
    "int2item = {v: k for k, v in item2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>users_enc</th>\n",
       "      <th>items_enc</th>\n",
       "      <th>ratings</th>\n",
       "      <th>predictions</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apt Pupil (1998)</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.933583</td>\n",
       "      <td>0.066417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peacemaker, The (1997)</td>\n",
       "      <td>625.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.018129</td>\n",
       "      <td>2.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crash (1996)</td>\n",
       "      <td>625.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.743651</td>\n",
       "      <td>1.743651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Starship Troopers (1997)</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.014387</td>\n",
       "      <td>2.014387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Devil's Own, The (1997)</td>\n",
       "      <td>625.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.989292</td>\n",
       "      <td>2.989292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  users_enc  items_enc  ratings  predictions   \n",
       "0          Apt Pupil (1998)      625.0     1489.0      5.0     4.933583  \\\n",
       "1    Peacemaker, The (1997)      625.0      994.0      3.0     5.018129   \n",
       "2              Crash (1996)      625.0      308.0      3.0     4.743651   \n",
       "3  Starship Troopers (1997)      625.0     1325.0      3.0     5.014387   \n",
       "4   Devil's Own, The (1997)      625.0      224.0      2.0     4.989292   \n",
       "\n",
       "      error  \n",
       "0  0.066417  \n",
       "1  2.018129  \n",
       "2  1.743651  \n",
       "3  2.014387  \n",
       "4  2.989292  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos las diferencias...\n",
    "data = torch.vstack([users, items, ratings, scaled_predictions]).detach().cpu().numpy().T\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_records(data, columns=[\"users_enc\", \"items_enc\", \"ratings\", \"predictions\"])\n",
    "df.insert(loc=0, column=\"title\", value=df.items_enc.map(int2item))\n",
    "df[\"error\"] = abs(df.ratings - df.predictions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Til There Was You (1997)</th>\n",
       "      <td>1.388391</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101 Dalmatians (1996)</th>\n",
       "      <td>1.296285</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <td>0.528588</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187 (1997)</th>\n",
       "      <td>1.362163</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 Days in the Valley (1996)</th>\n",
       "      <td>1.154927</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                error  count\n",
       "title                                       \n",
       "'Til There Was You (1997)    1.388391      4\n",
       "101 Dalmatians (1996)        1.296285     12\n",
       "12 Angry Men (1957)          0.528588     23\n",
       "187 (1997)                   1.362163     11\n",
       "2 Days in the Valley (1996)  1.154927     17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df = df.groupby([\"title\"]).agg(error=(\"error\", \"mean\"), count=(\"title\", \"count\"))\n",
    "errors_df.sort_values(by=\"error\", ascending=True)\n",
    "\n",
    "# Movies with lower error\n",
    "errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)</th>\n",
       "      <td>4.086637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In the Army Now (1994)</th>\n",
       "      <td>4.081493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mighty Morphin Power Rangers: The Movie (1995)</th>\n",
       "      <td>4.073963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herbie Rides Again (1974)</th>\n",
       "      <td>4.055377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ciao, Professore! (1993)</th>\n",
       "      <td>4.023501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       error  count\n",
       "title                                                              \n",
       "Old Lady Who Walked in the Sea, The (Vieille qu...  4.086637      1\n",
       "In the Army Now (1994)                              4.081493      1\n",
       "Mighty Morphin Power Rangers: The Movie (1995)      4.073963      1\n",
       "Herbie Rides Again (1974)                           4.055377      1\n",
       "Ciao, Professore! (1993)                            4.023501      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movies with biggest errors\n",
    "errors_df.sort_values(by=\"error\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
